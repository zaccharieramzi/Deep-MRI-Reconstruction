{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this just to make sure we are using only on CPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/volatile/home/Zaccharie/workspace/Deep-MRI-Reconstruction/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os.path as op\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from cascadenet_pytorch.model_pytorch import DnCn\n",
    "from data_torch import MaskedUntouched2DDataset, MaskedUntouched2DAllLoadedDataset\n",
    "from torch_training import fit_torch, torch_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "train_path = '/media/Zaccharie/UHRes/singlecoil_train/singlecoil_train/'\n",
    "val_path = '/media/Zaccharie/UHRes/singlecoil_val/'\n",
    "test_path = '/media/Zaccharie/UHRes/singlecoil_test/'\n",
    "\n",
    "n_samples_train = 34742\n",
    "n_samples_val = 7135\n",
    "\n",
    "n_volumes_train = 973\n",
    "n_volumes_val = 199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "# generators\n",
    "AF = 4\n",
    "# train_gen = MaskedUntouched2DAllLoadedDataset(train_path, af=AF, inner_slices=1)\n",
    "train_gen = MaskedUntouched2DDataset(train_path, af=AF, inner_slices=1)\n",
    "val_gen = MaskedUntouched2DDataset(val_path, af=AF)\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_gen,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=35,\n",
    "#     pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_gen,\n",
    "    batch_size=1,\n",
    "    num_workers=35,\n",
    "#     pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cascadenet_orig_torch_af4_1567439027\n"
     ]
    }
   ],
   "source": [
    "run_params = {\n",
    "    'nc': 5,  # n cascade\n",
    "    'nd': 5,  # n convs\n",
    "    'nf': 64,  # n filters\n",
    "}\n",
    "n_epochs = 100\n",
    "run_id = f'cascadenet_orig_torch_af{AF}_{int(time.time())}'\n",
    "chkpt_path = f'checkpoints/{run_id}' + '-{epoch:02d}.hdf5'\n",
    "log_dir = op.join('logs', run_id)\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating D5C5\n"
     ]
    }
   ],
   "source": [
    "model = DnCn(**run_params)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfit_epoch(model, data, optimizer, device):\n",
    "    model.train()\n",
    "    kspace, mask, image_gt = data\n",
    "    kspace = kspace[0]\n",
    "    mask = mask[0]\n",
    "    image_gt = image_gt[0]\n",
    "    kspace = kspace.to(device)\n",
    "    mask = mask.to(device)\n",
    "    image_gt = image_gt.to(device)\n",
    "    image_pred = model(kspace, mask)\n",
    "\n",
    "    loss = F.l1_loss(image_pred, image_gt)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    psnr = torch_psnr(image_pred, image_gt)\n",
    "    print('Training PSNR:', psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8013c6076c4e40dfa5e8c708cf873a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PSNR: tensor(2.6834, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(-1.8862, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(1.1830, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(11.5652, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(6.8393, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(4.5380, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(7.0447, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(15.7987, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(14.5460, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(10.4893, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(11.2694, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(16.8111, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(23.8209, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(16.3975, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(16.1583, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(20.2643, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(28.0665, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(20.5738, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(20.5566, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(25.6364, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(27.0099, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(22.6790, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(24.5073, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.3604, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(24.2683, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(23.7378, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(25.7265, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(31.9085, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(26.9235, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(28.0683, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.8907, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(28.4588, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(28.9637, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.3607, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(28.8927, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(29.0326, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.2019, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(28.2110, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(29.1370, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.6044, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(28.3827, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(29.1074, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(29.5700, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.9151, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(29.9636, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.7262, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(30.5083, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(31.3414, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.0825, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(29.4036, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.1737, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(30.9097, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.0873, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.9381, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(31.9376, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.8435, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.3597, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(31.9935, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.3668, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.4420, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.5378, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.0348, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.8991, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.9099, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.4860, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(30.6889, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.3930, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.6512, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.6092, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.5222, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(30.2249, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.8131, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(31.7598, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.7811, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(30.1621, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.4573, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.6813, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.2698, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.5183, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.5687, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(31.9724, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.3959, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.2090, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(38.4035, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.6193, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.9611, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.4279, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(31.7923, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(38.4959, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.8586, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.9686, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.4003, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.0058, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.8509, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(30.6782, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.6264, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.3553, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.2342, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.2482, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.4916, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.2360, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.6790, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.2894, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.4629, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.5174, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.7341, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(31.8848, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.1403, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(31.5662, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.9763, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(31.4739, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.0934, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.1046, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.1599, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.6441, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.6675, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.4925, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.3467, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.3889, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.6922, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.7072, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.1950, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.3296, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.5672, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(31.0836, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.4776, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.6501, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.8788, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.5668, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.6355, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.0692, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.5514, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.6741, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.6772, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.4914, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.4945, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.8912, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.5726, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.0044, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.7507, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.0370, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.8045, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.2716, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.7101, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(32.9750, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.7466, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.0246, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.6621, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.5450, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.9950, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PSNR: tensor(35.6274, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.1370, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(38.1942, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(33.5076, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.9246, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.4131, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.0931, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.1122, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.3224, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.6400, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.1441, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(38.7764, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.6908, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.9845, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.1309, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.5988, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.7908, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.2158, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(37.3872, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.4242, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.6839, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(36.2841, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.1252, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(34.2880, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(35.1139, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(38.3539, grad_fn=<MulBackward0>)\n",
      "Training PSNR: tensor(38.5916, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i, data = next(enumerate(train_loader))\n",
    "for _ in tqdm_notebook(range(500)):\n",
    "    overfit_epoch(model, data, optimizer, 'cpu')\n",
    "#     overfit_epoch(model, data, optimizer, 'cuda')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
